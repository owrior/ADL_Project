{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/intermediate/td_data.csv')\n",
    "stations = gpd.read_file('data/intermediate/stations.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now breaking the stations down and looking at missing CO values as well as length of time reported for (26280 reports is 3 years). Some stations report 100 % missing values for their whole time periods which will be neglected from the set. Those remaining are present for much more of the year as well as having almost complete NOx and NO2 reading which could be used to predict some of the missing CO values. However two of the remaining stations are missing O3, PM10 and SO2 for the whole time period, and in addition they have only reported for about a third of the time period, therefore these will also be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = df[df['station'] != 0].isnull().sum().sort_values() / len(df[df['station'] != 0])\n",
    "predictors = list(missing_percent[(missing_percent <= missing_percent['CO']) & (missing_percent > 0)].index)\n",
    "\n",
    "def get_null_perc(x, dfin, keep_length=False, grpby=['station']):\n",
    "    xna = '_'.join([x, 'na'])\n",
    "    df = dfin.copy()\n",
    "    df[xna] = df[x].isnull()\n",
    "    \n",
    "    sm = df[['station', xna, 'date']].groupby(grpby).agg(\n",
    "        length=(xna, 'size'),\n",
    "        na_sum=(xna, 'sum'), \n",
    "        mindate=('date', 'min'), \n",
    "        maxdate=('date', 'max')\n",
    "    )\n",
    "    \n",
    "    sm['_'.join([xna.lower(), 'perc'])] = sm['na_sum'] / sm['length'] * 100\n",
    "    sm = sm.filter(regex='perc|date|length').reset_index()\n",
    "    return(sm)\n",
    "\n",
    "dfin = df\n",
    "\n",
    "sm = get_null_perc(predictors[0], dfin)\n",
    "for x in predictors[1:]:\n",
    "    sm = sm.merge(get_null_perc(x, dfin), on=['station', 'length', 'mindate', 'maxdate'], how='inner')\n",
    "\n",
    "# print(sm)\n",
    "\n",
    "# Filtering out stations with with large number of missing values for CO and missing parts of the year.\n",
    "chosen_station_id = sm.loc[(sm['co_na_perc'] < 30), 'station'].values.tolist() + [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging on the chosen station information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_stations = stations[stations['station'].isin(chosen_station_id)]\n",
    "\n",
    "keep = ['station', 'date', 'lon', 'lat', 'elevation', 'sin_time', 'cos_time', 'sin_month', 'cos_month']\n",
    "df2 = df.merge(chosen_stations[['station', 'lon', 'lat', 'elevation']], on='station', how='inner')[keep + predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df2.copy()\n",
    "\n",
    "X = dft[dft['station'] != 0].to_numpy()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "imputer = IterativeImputer(max_iter=100, \n",
    "                           random_state=0, \n",
    "                           tol=1e-4, \n",
    "                           skip_complete=True,\n",
    "                           estimator=BayesianRidge())\n",
    "\n",
    "X_p = np.concatenate((X[:, :2], imputer.fit_transform(X[:, 2:])), axis=1)\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "df3 = pd.DataFrame().from_records(X_p)\n",
    "df3.columns = df2.columns.tolist()\n",
    "\n",
    "df3['NA'] = np.where(df2.isnull(), 1, 0)\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing 3d kriging (using lon, lat, elevation) with the 2d kriging (lon, lat) the difference in estimate is very small (~%) and therefore due to the execution time being doubled I have opted to use 2d in the interest of time (though the 3d has also been included). Some of the values for PM10 (which have not been imputed) are 5 mg/m3 for all stations. This creates an error for the krigging and therefore the value for the ADL HQ has been given the same value (this is most likely due to the concentration being below a minimum read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.copy()\n",
    "df7 = df7.append(dft[dft['station'] == 0], ignore_index=True)\n",
    "\n",
    "adl_loc = stations[stations['name'] == 'ADL HQ'][['lon', 'lat', 'elevation']]\n",
    "adl_lon = adl_loc['lon']\n",
    "adl_lat = adl_loc['lat']\n",
    "adl_elev = adl_loc['elevation']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for p in predictors:\n",
    "    for d in df6.date.unique():\n",
    "        try:\n",
    "            OK = OrdinaryKriging(\n",
    "                df6.loc[df6.date == d, 'lon'].values,\n",
    "                df6.loc[df6.date == d, 'lat'].values,\n",
    "                df6.loc[df6.date == d, p].values,\n",
    "                coordinates_type='geographic',\n",
    "                variogram_model='linear'\n",
    "            )\n",
    "            z, ss = OK.execute('points', adl_lon, adl_lat)\n",
    "        except:\n",
    "            print(p)\n",
    "            print(d)\n",
    "            l = df6.loc[df6.date == d, p].values.tolist()\n",
    "            if np.mean(l) - l[0] == 0:\n",
    "                z = np.mean(l)\n",
    "            else:\n",
    "                z = np.NaN\n",
    "            \n",
    "        df7.loc[(df7.date == d) & (df7.station == 0), p] = z\n",
    "    print(p)\n",
    "    print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
