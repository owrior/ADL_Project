{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First reading in and shaping the historic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/measurements/time_series_data_2016.csv\n",
      "data/measurements/time_series_data_2017.csv\n",
      "data/measurements/time_series_data_2018.csv\n"
     ]
    }
   ],
   "source": [
    "measure_files = [\"data/measurements/\" + x for x in os.listdir(\"data/measurements\")]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file in measure_files:\n",
    "    print(file)\n",
    "    df = df.append(pd.read_csv(file), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "df2 = df.copy()\n",
    "\n",
    "mg_tb = pd.DataFrame(columns=['date', 'station'])\n",
    "for stn in df2.station.unique().tolist() + [0]:\n",
    "    temp = pd.DataFrame({\n",
    "        'date': pd.date_range(df2.date.min(), df2.date.max(), freq='h'),\n",
    "        'station': stn\n",
    "    })\n",
    "    mg_tb = mg_tb.append(temp, ignore_index=True)\n",
    "    \n",
    "df2 = df2.merge(mg_tb, on=['date', 'station'], how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now creating cyclical time (cos and sin seconds after midnight) and cyclical months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "# Getting seconds after midnight.\n",
    "df3['seconds'] = df3['date'].dt.hour * 3600 + df3['date'].dt.minute * 60 + df3['date'].dt.second\n",
    "\n",
    "# Transforming to 2D.\n",
    "seconds_in_day = 24*60*60\n",
    "df3['sin_time'] = np.sin(2*np.pi*df3.seconds/seconds_in_day)\n",
    "df3['cos_time'] = np.cos(2*np.pi*df3.seconds/seconds_in_day)\n",
    "\n",
    "# Getting month.\n",
    "df3['months'] = df3['date'].dt.month - 1\n",
    "\n",
    "# Transforming to 2D.\n",
    "max_month = 11\n",
    "df3['sin_month'] = np.sin(2*np.pi*df3.months/max_month)\n",
    "df3['cos_month'] = np.cos(2*np.pi*df3.months/max_month)\n",
    "\n",
    "df3.drop(columns=['seconds', 'months'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data on stations and adding data for ADL HQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in station attribute file and appending ADL HQ details.\n",
    "attr = pd.read_csv(\"data/station/attributes.csv\")\n",
    "attr = attr.append({'name': 'ADL HQ', \n",
    "                    'id': 0,\n",
    "                    'address': 'Paseo de la Castellana, 13, 28046 Madrid, Spain',\n",
    "                    'elevation': 691}, ignore_index=True)\n",
    "\n",
    "# Reading in geojson file and appending ADL HQ details.\n",
    "stations = gpd.read_file(\"data/station/locations.geojson\")\n",
    "stations = stations.append({'id': 0, \n",
    "                          'lon': -3.688163914, \n",
    "                          'lat': 40.439664908, \n",
    "                          'geometry': Point(-3.688163914, 40.439664908)}, \n",
    "                         ignore_index=True)\n",
    "\n",
    "# Merging the two together.\n",
    "stations = stations.merge(attr, on='id', how='left')\n",
    "\n",
    "# Creating an indicator for the legend.\n",
    "stations['HQ'] = np.where(stations['name'] == 'ADL HQ', 'ADL Headquarters', 'Station')\n",
    "\n",
    "# Renaming id to station\n",
    "stations.rename(columns={'id': 'station'}, inplace=True)\n",
    "\n",
    "# Merging on stations.\n",
    "df4 = df3.merge(stations[['station']], on='station', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to intermediate file for exploration and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"data/intermediate/td_data.csv\", index=False)\n",
    "stations.to_file(\"data/intermediate/stations.shp\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
